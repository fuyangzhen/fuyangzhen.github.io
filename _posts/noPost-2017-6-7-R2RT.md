---
layout: noPost
title: "R2RT LSTM 翻译"
tags: [翻译, R2RT, LSTM]
date: 2017-07-7T00:00:00-04:00
---

##1 Information morphing and vanishing and exploding sensitivity
##1 信息变形、发散和爆炸的敏感性
把整个世界当做一个RNN来考虑：从前一时刻到下一个时刻，整个世界被一个叫做时间的异常复杂的递归函数所修改。现在，考虑一下今天的一个小改变将会在100年的时间内对整个世界造成怎样的影响。可能如同蝴蝶效应一般引发地球另一侧的台风，也有可能和我们今天的行为没有任何关系。假如爱因斯坦没有发现相对论，那么1950年就会变得不同，但是或许其他人能够发现相对论，以至于到2000年时，这个影响会变小，并最终到2050年时造成的影响几乎消失。

请注意，在爱因斯坦的例子中，过去的改变是新信息的引入（相对论理论），而且更一般地，这个新信息的引入是我们递归函数（时间的流动）的直接作用结果。因此我们可以把信息本身当作一种改变，其被递归函数改变，导致消失，爆炸或者简单波动。

上面的讨论表明世界的状态（或者RNN）是持续改变的，现在能够对过去的变化极为敏感或极不敏感：影响能够复合或者消失，这些问题能够推广到RNN上（以及前馈型NN）：

1.信息的变形
首先，如果信息在不断变化，那当我们需要的时候就会很难发掘出合适的信息。信息的最佳可用状态可能发生在过去的某个时刻。另外（on top of）学习如何发掘今天的信息，如果可能的话，我们还必须学会从现在的状态中解码出初始的状态。这导致了学习的困难性和差的结果。

很容易就能证明信息的改变在普通的RNN中发生了，事实上，假设一个RNN元胞在没有外部输入的情况下保持其先前的状态的完整是可能的。那么，$F(x)=ϕ(Ws_{t−1}+b)$就应该是关于$s_{t−1}$的恒等式，但是恒等式应该是线性的，但是F(x)是非线性的。所以产生了矛盾。因此，RNN细胞就不可避免地从一个时间步骤到下一个步骤上改变了状态。甚至最简单的任务输出$s_t=x_t$对普通的RNN来说也是不可能的。

这就是被称作退化问题的根本原因（见 He et al） 。该论文的作者称这个现象是意想不到和违反直觉的。但是我想说的是退化问题或则信息变形是真的挺常见的（有许多例子可以说明），尽管信息变形不是介绍LSTM的原始动机，但是LSTM背后的原理恰巧有效地解决了这个问题。事实上，He et al所用的参与网咯的有效性正是LSTM基本原则的作用结果。

2.梯度的消失和爆炸
第二，我们训练RNN使用了反响传播算法。但是，反向传播算法是一种基于梯度的算法，消失和爆炸的敏感性是对梯度的消失和爆炸的另一种说法（后者是更为公认的叫法，但是我觉得前者更有描述性）。如果梯度爆炸了，我们就没法训练我们的模型了。如果梯度消失了，那么我们就很难学得长期的依赖了，因为反向传播会对最近杂音很敏感，这就会使训练变得困难。

等下我会通过反向传播来继续讲解训练RNN的困难之处，但首先我要给出普通RNN是如何很轻易就梯度消失了的简单证明，并且我们应该如何在训练之初避免它。

##2 消失敏感性的数学充分条件
令$s_t$为在时间$t$时的状态向量，令$\Delta{s_t}$为在时刻$t$引发的状态向量的改变。我们的目标是要证明导致梯度消失在数学上的充分条件：当$$n\to\infty$时，由时间步骤$t$的状态改变引起的在时间步骤$t+k$的改变将会消失，我们将为下式证明一个充分条件：

$$\lim_{k\to\infty}\frac{\Delta{s_t}}{\Delta{s_t}}=0$$
从我们对普通RNN细胞的定义出发，我们有：

$$s_{t+1}=\phi(z_t)\quad其中\quad z_t=Ws_t+Ux_{t+1}+b$$

在几个变量中运用中值定理，我们可得存在$c \in [z_t, z_t+\Delta z_t]$使得:

$$
\Delta s_{t+1}=[\phi^{'}(c)]\Delta z_t\\
\quad\quad\quad\;\;=[\phi^{'}(c)]\Delta (Ws_t)\\
\quad\quad\quad=[\phi^{'}(c)]W\Delta s_t
$$
现在令$\Vert A \Vert$表示矩阵2-范数，$\rvert v\rvert$表示欧几里得向量范数，并定义：
$$\gamma = \sup_{c \in [z_t,\ z_t + \Delta z_t]}\Vert [\phi'(c)] \Vert \\$$
注意对于sigmoid函数，$\gamma \leq \frac{1}{4}$,对于tanh函数$\gamma \leq 1$
对等式两侧取向量范数，再先后两次矩阵2-范数和上确界的定义可得不等式如下：
$$
\begin{split}
\rvert\Delta s_{t+1}\rvert & = \rvert[\phi'(c)]W\Delta s_t\rvert\\
& \leq \Vert [\phi'(c)] \Vert \Vert W \Vert \rvert\Delta s_{t}\rvert\\
& \leq \gamma \Vert W \Vert \rvert\Delta s_{t}\rvert\\
& = \Vert \gamma W \Vert \rvert\Delta s_{t}\rvert
\end{split}
$$
在扩展这个公式$k$次之后，我们得到$\rvert\Delta s_{t+k}\rvert \leq \Vert \gamma W \Vert^k \rvert\Delta s_{t}\rvert$,即：
$$
\frac{\rvert\Delta s_{t+k}\rvert}{\rvert\Delta s_t\rvert} \leq \Vert \gamma W \Vert^k.
$$
因此，若$\Vert \gamma W \Vert < 1$,我们可知$\frac{\rvert\Delta s_{t+k}\rvert}{\rvert\Delta s_t\rvert}$会随时间呈指数递减，并已经证明得出下式的一个充分条件：
$$
\lim_{k \to \infty}\frac{\Delta s_{t+k}}{\Delta s_t} = 0.
$$
何时$\Vert \gamma W \Vert < 1$?$\gamma$被sigmoid函数限定到$\frac{1}{4}$以内，被tanh函数限定到1以内，这就告诉我们导致梯度消失的充分条件是$\Vert W \Vert$要对应于各自的激活函数小于4或者1。
我们从上面的证明可立即知道的是，如果我们对权重$W$初始化得太小，我们的RNN可能会因为消失的梯度从而不能立即学得任何东西。现在我们扩展分析，来决定出权重合适的初始化。
##3 为了避免梯度消失最小化权重初始化
首先，让我们假设取$\phi = \tanh$且$\gamma = 1$。
我们的目标是找到$W$的初始化使得：
1.$\Vert \gamma W \Vert = 1$
2.或者我们尽可能地让上式相等。
对于第1点以内为我们已另$\gamma$等于1，所以我们可得$\Vert W \Vert = 1$
对于第2点，我们应该试着把$W$所有的奇异值都设置为1，而不仅是最大。那么，如果$W$所有的奇异值都等于1的话，那就意味着$W$每一列的范数都是1（因为对于基向量$e_i$每一列就可以表示为$We_i$，我们就有$\rvert We_i\rvert = \rvert e_i\rvert = 1$）那就意味着对于列$j$我们有：
$$
\Sigma_{i}w_{ij}^2 = 1
$$
在第$j$列中有$n$个元素，我们从相同的随机分布中来选择它们，所以让我们找到一个随机权重$w$的分布满足:
$$n\mathbb{E}(w^2) = 1$$
现在假设我们想让$w$的初始化值均匀地分布在区间$[-R,\ R]$中，并且$w$的均值是0,定义$\mathbb{E}(w^2)$为其方差$\mathbb{V}(w)$。在区间$[a,\ b]$内均匀分布的方差为$\frac{(b-a)^2}{12}$,从中可得$\mathbb{V}(w) = \frac{R^2}{3}$。带入方差可得：
$$
n\frac{R^2}{3} = 1
$$
得出：
$$
R = \frac{\sqrt{3}}{\sqrt{n}}
$$
这就表明我们初始化的权重应该在均匀分布的区间内：
$$
\bigg[ -\frac{\sqrt{3}}{\sqrt{n}},\ \frac{\sqrt{3}}{\sqrt{n}}\bigg].
$$
这是一个很好地结果，因为它是平方权重矩阵的Xavier-Glorot初始化，也同时出自另外的想法推到得来。Xavier-Glorot初始化由[Glorot and Bengio (2010)](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)发明，已在实践中被证明是一种有效地权重初始化。更一般地，Xavier-Glorot处理运用到在拥有倒数在原点处接近1的激活函数的$m$行$n$列的权重矩阵当中，并且说应该按照区间如下的均匀分布来初始化权重：
$$
\bigg[-\frac{\sqrt{6}}{\sqrt{m + n}},\ \frac{\sqrt{6}}{\sqrt{m + n}}\bigg]
$$
当你使用其他激活函数的时候，按照上面的分析流程你可以很容易就得出初始化方法，并能得出权重应该依照的不同的随机分布（如高斯分布等）。
##4 随着时间的反向传播算法和消失敏感性
用反向传播算法来训练RNN和用反向传播算法来训练前馈型NN是很相似的。

1.我们通过时间来反向传递误差

对于RNN我们需要反向传播误差从现在的RNN细胞穿过状态，穿过时间，到达以前的RNN细胞。这就可以使RNN学些捕获到长时期的时间依赖，因为模型的参数在穿过RNN细胞被共享了（每个RNN细胞有着同一权重和偏差），我们需要单独计算每个时间步骤的梯度，然后把它们加起来。这和其他模型（如CNN）中的传播误差来共享参数是类似的。

2.在权重更新频率和梯度的准确性之间有个权衡

对于所有的基于梯度的训练算法，不可避免地都要对(1)参数的更新频率和(2)准确的长时期梯度之间进行权衡。为了明白这一点，请考虑当我们在每个步骤中更新梯度的时候发生了什么，然而误差反向传播可不止一步：

1. 在时间$t$我们使用当前的权重$W_t$，来计算当前的输出$0_t$和当前的状态$s_t$
2. 第二步，我们用$0_t$来运行一次反向传播并更新$W_t$到$W_{t+1}$
3. 第三步，在时间$t+1$，我们用$W_{t+1}$和步骤1中用原始$W_t$计算得出的$s_t$来共同计算$0_{t+1}$和$S_{t+1}$
4. 最后，我们用$0_{t+1}$来运行一次反向传播。但是$0_{t+1}$是用$S_t$计算得出的，$S_t$又是用$W_{t}$计算得出的(不是$W_{t+1}$)，这就意味着我们为权重计算的梯度在时间步骤$t$是用我们旧的权重$W_{t}$来评估的，而不是当前的权重$W_{t+1}$。因此，这里只有一个对梯度的估计，如果它是关于当前权重的计算，这个影响会在我们反向传播误差更远的时候混合起来。
我们能通过更新更多的参数计算得出更为准确的梯度(反向传播)，但是我们可能需要放弃训练速度(在训练的初期害处会特别的明显)。请注意，这和为小批量梯度下降权衡选择一个小批量的大小类似：批量越大，对梯度的估计越准确，但是同时能被更新的梯度就会更少。

我们还可以选择不将错误传播回比参数更新的频率更多的步骤，但是我们的代价是就不能计算出关于权重完整的梯度。

3.梯度的消失加上被分享的参数意味着不平衡的梯度流动和对近期的扰动的过分敏感

在前馈型神经网络中，指数级消失的梯度意味着在早期的神经层里对权重造成的改变将会远小于对后期神经层造成的改变。这是很失败的，我们得训练网络达到很长很长的时间，才能使得早期的神经层得到学习，为了说明这点，考虑下在训练过程中，早期的神经层和后期的神经层是如何彼此交流的。早期层初始时发送出原始信号，后期层很快就能解释这些信号。但是接下来早期层应该要学会产生更好的原始信号而不是更精准的信号。

在RNN中这种情况更糟糕，因为不像前馈型网络，权重在早期层和后期层中是被共享的。这就意味着，不仅是简单的无法交流，它们能够直接抵消：特定权重的梯度可能会在早期层中是积极的，但是到了后期层中就变成消极的了，这导致了整体梯度的消极，以至于早期层无法按照预想的速度来学习。按照 Hochreiter and Schmidhuber (1997)的话来说就是：“通过时间反向传播对近期的干扰泰国敏感了。”

4.因此实施截断型反向传播就很有意义了

在训练中我们限制反向传播误差时的步数被称作是截断型反向传播，立即能注意到，如果我们拟合的输入/输出序列是无限长的，我们就必须得使用截断反向传播了，否则我们的算法将停止向后传递。如果序列长度是有限，但是仍然很长，我们出于对计算可行性的考虑可能也需要使用该方法。

另外，消失梯度也为我们实施截断反向传播提供了另一个理由。如果我们的梯度消失了，那么已经反向传播了多不的梯度就会变得特别小，对训练能造成的影响就可以忽略不计了。

我们选择的不仅是使用截断反向传播的频率，也是在选择更新模型参数的频率。

5.还有一些梯度分量正向传播的事情（bad performance）

##5 处理消失和爆炸的梯度

如果我们的梯度爆炸了，那反向传播就没法运作了，应为我们将子啊早期层中得到`NaN`。对此，一个简单的解决方法是修剪梯度到一个最大值，这个被[Mikolov (2012)](http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf)，这样就能在实践中预防`NaN`并使训练继续。

从上面我们看到好的权重初始化是相当重要的，但这只影响训练的初期，那么后来的训练呢？[Pascanu et al. (2013)](http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf)中的方法引入一个正则化项来不断地强迫反向传播误差的流动。但是不幸的是，很难找到一个理由来支持说这个方法任何时候都有效。

然而对于某些任务，我们希望梯度完全消失，而对某些其他任务，或许我们想让它们增长。在这些例子中，正则化将会降低模型的性能，并且似乎没有证据能说明某个情形是最普适的。LSTM避免了这个问题。

##6 写入记忆：LSTM背后的直觉

和传话的儿童游戏很相像，信息被RNN改变而且初始信息丢失。一个原始信息中的小的改变可能不会对最终的信息造成任何不同，它或许也可能导致完全的不同。

我们如何才能保存信息的完整呢？LSTM的基本原理是:为了确保我们现实世界中的信息的完整，我们把它们写下来。写是对当前状态的一个增量：它是一种创造行为（用笔写在纸上）或者毁坏行为（刻在石头上）；当你写下这个话题并且在误差梯度不断反向传播的时候，话题本身并不会改变。

这在[Hocreiter and Schmidhuber](http://isle.illinois.edu/sst/meetings/2015/hochreiter-lstm.pdf)发表的里程碑式的论文中对LSTM有精确的描述，其中：”我们如何才能在对自身有单个连接的单个单元获得连续不断的误差流？“

答案很简单，那就是避免信息的改变：一个LSTM状态的改变是明确的写入，通过直接的增加或者减少，从而状态中的每个元素在没有外界干扰的前提下能保持不变:"单元的激活必须保持不变，这将通过使用恒等函数来确保。"

> The fundamental principle of LSTMs: Write it down.
> 为了确保我们现实世界中的信息的完整，我们把它们写下来。写是对当前状态的一个增量：它是一种创造行为（用笔写在纸上）或者毁坏行为（刻在石头上）；当你写下这个话题并且在误差梯度不断反向传播的时候，话题本身并不会改变。
> 准确地说，这就意味着任何状态的改变都是增量，使得$s_{t+1} = s_t + \Delta s_{t+1}$(此处的$\Delta$是从一个步骤到下一个步骤，上面提到的$\Delta$是处于同一时间步骤的两个状态向量)

但是Hochreiter和Schmidhuber提到的'写下来'之前已被尝试过了，但效果不甚理想。
我们的一些写入是积极的，一些是消极的，所以我们的画布定会爆炸不是真的：
我们的写入可能理论上会相互抵消。然而事实证明，如何来协调两者是相当困难的，。尤其在训练伊始，我们以随机初始化开始，网络是由一些非常随机的记录形成的。即使我们最终学会了如何协调写入，那也很难记录下任何有用的东西。这是LSTM面临的根本挑战，不受控制且不协调的写入造成的混乱和溢出是非常难以恢复的。
Hochreiter和Schmidhuber认识到了这个问题，把它分成了几个子问题，那就是：”输入权重的冲突“、”输出权重的冲突“、”滥用问题“和”内部状态漂移“。LSTM结构被小心地设计从而克服这些问题。

##7 选择性地控制和协调写入
通过早期的LSTM的我呢县，克服LSTM的基本挑战和保持状态受控的关键是选择：写入什么，读取什么（因为我们需要读取一些东西才能知道应该写入什么）和忘记什么（因为无用的信息是种干扰，需要被忘记）。

状态变得如此混乱的部分原因是对RNN状态每个元素的写入。这是一个我遇到很多次的问题。字啊我的的电脑前有一张纸，我在上面写下很多事情。当它写满了我就拿出它下面的新纸，然后继续写。循环往复，结束时我就得到了一堆纸字啊我的书桌上，上面包含了大量乱码文件。

Hochreiter和Schmidhuber将这个现象描述为”输入权重的冲突“：如果在每个时刻每个单元被所有的单元写入，那么它将会收集到大量无用信息，无法还原其原始状态。因此，RNN必须学会如何使用它其中某些单元来取消其他输入写入和”保护“状态。
>首先要进行的选择：写入选择
>为了充分利用我们在现实世界中的记录，我们需要对我们写的东西有所选择; 当采取类笔记时，我们只记录最重要的点，我们当然不会在我们的旧笔记上面写我们的新笔记。为了使我们的RNN细胞这样做，他们需要一种选择性记录机制。

我们的状态可以变得混乱的第二个原因是第一个的反面：为了它做出的每个写入，基础的RNN会读取状态的每个元素。举个例子：我可能在写这篇文章的同时正在国家公园度假，遇到一头放养的熊。我可能在文章中记下我所读过的关于如何安全与熊相处的东西。这只是一件事，只有轻微的混乱，但想象下如果我写下所有的见闻这篇文章会是什么样子...

Hochreiter和Schmidhuber将此描述为“输出权重冲突”：如果在每个时间步长不相关的单元读取了所有其他单元，则它们会产生潜在的大量不相关信息。因此，RNN必须学习如何使用它的一些单元来消除导致学习困难的不相关的信息。

注意读取和写入之间的区别：如果我们选择不从一个单元读取，它就不能影响我们的状态的任何元素，我们的读取决定影响了整个状态。 如果我们选择不写给一个单位，这只影响我们状态的单一元素。 这并不意味着选择性读取的影响比选择性写入的影响更重要：读取被加在一起并被非线性压缩，而写入是绝对的，因此读取决定的影响是宽泛但浅的，写入决策的影响很窄但很深远。
> 第二种形式的选择性：有选择地读取
> 为了在实际中表现良好，我们需要应用最相关的知识来选择性读取。为了使我们的RNN细胞需要一种选择性阅读的机制来这样做。
第三种形式的选择性涉及我们如何处置不再需要的信息。我的旧纸笔记被扔掉。否则，即使我是选择性的写入我最终也会得到大量的纸张。在我的Dropbox中未使用的文件被覆盖，否则我会耗尽空间，即使我是选择性地创建它们。

这种直觉在最初的LSTM论文中没有介绍，这导致原始的LSTM模型在涉及长序列的简单任务中会遇到麻烦。Gers等人 （2000）的论文中指出，在某些情况下，原始LSTM模型的状态将无限地增长，最终导致网络崩溃。 换句话说，原来的LSTM遭受信息过载了。

>第三种形式的选择性：选择性地忘记。

>在现实世界中，我们只能同时记住有限多的事情; 为了为新信息腾出空间，我们需要选择性地忘记最不相关的旧信息。 为了我们的RNN细胞也能这样做，他们需要一种选择性遗忘的机制。
这样，导出LSTM只需要两个步骤：

我们需要确定选择性的机制，并且我们需要把这些机制结合在一起。

##8 作为选择性机制的阀门
选择性读取、写入和忘记涉及状态的每个元素的单独的读，写和忘记。我们将通过利用和状态一样大小的读，写和忘记向量来做出这些决定，其值在0和1之间，这个数值指定了对于每个状态元素执行的读，写和忘记的百分比。请注意，虽然将阅读，写作和遗忘视为二元决策可能更自然，但我们需要通过可微函数实现决策。 逻辑Sigmoid是一个自然选择，因为它是可微的，并产生0和1之间的连续值。

我们称这些读，写和忘记向量为“门”，我们可以使用我们所拥有的最简单的函数来计算它们，就像我们对于普通RNN的单层神经网络所做的那样。我们的三个门在时间步骤t表示为：$i_t$输入门(用于写入)，$o_t$输出门（用于读取）和$f_t$遗忘门（用于记忆）。从这些名字上，我们立即注意到LSTM的两个事情是倒退：

不可否认，这是一个鸡生蛋生鸡的问题，但我通常会先想到读，然后才是写。 实际上，RNN单元规范强烈建议这种排序——我们需要在写入新的状态之前读取先前的状态，这样即使我们从一个空白的初始状态开始，我们也要读取它。输入门和输出门的名字表明LSTM采用的时间顺序关系。我们将看到这使架构复杂化。

忘记门用于忘记，但它实际上它是为了记忆而存在的门。 例如，忘记门向量中的1意味着记住一切，而不是忘记一切。 虽然这没有实际的区别，但可能会混淆。下面是门的数学定义（注意相似性）：
$$
\begin{split}
i_t &= \sigma(W_is_{t-1} + U_ix_t + b_i) \\
o_t &= \sigma(W_os_{t-1} + U_ox_t + b_o) \\
f_t &= \sigma(W_fs_{t-1} + U_fx_t + b_f) \\
\end{split}
$$
我们可以为门设计使用更复杂的功能。 一个简单而有效的最近的例子是使用“乘法积分”。 参见[Wu et al(2016)](https://arxiv.org/abs/1606.06630)让我们现在仔细看看我们的大门是如何相互配合的。
##9 把各个阀组合起来形成LSTM的原型
如果这里没有写入门，选择性地读取就是当读取先前的状态时我们需要使用读取门来产生下一次状态的写入。正如上面提到的，在单个RNN细胞的尺度内，读取很自然地先于写入。RNN基本原理表明我们的写入将会增量到以前的状态。因此，我们计算$\Delta s_t$，而不是$s_t$。我们把这个增量表示为$\tilde{s}_t$。

我们将以计算普通RNN状态的同一方式来计算$\tilde{s}_t$，除了不是使用先前的状态$s_{t-1}$，我们首先将先前的状态逐元素乘以读取门，以获得门的先前状态$o_t \odot s_{t-1}$：
$$
\tilde{s_t} = \phi(W(o_t \odot s_{t-1}) + Ux_t + b)
$$
注意$\odot$表示元素级乘法(点乘)，以及$o_t$表示的是我们的读门（输出门）。$\tilde{s}_t$是一个待定的写入，因为我们正在应用选择性写入，并有一个写门。 因此，我们用$\tilde{s}_t$乘以写门$i_t$，得出我们最终的写入$i_t \odot \tilde{s}_t$。

最后一步是将它添加到我们的先前状态，但忘记选择性，我们需要有一个忘记的机制。 因此，在我们将任何东西添加到我们的先前状态之前，我们将它乘以（点乘）忘记门（其实际上作为记忆门操作）。 我们的最终原型LSTM方程是：
$$
s_t = f_t \odot s_{t-1} + i_t \odot \tilde{s}_t
$$
如果我们把所有的方程组合在一起，我们得到我们的原型LSTM单元的完整公式（注意$s_t$也是每个时间步长的单元外部输出）：
**LSTM原型**
$$
\begin{split}
i_t &= \sigma(W_is_{t-1} + U_ix_t + b_i) \\
o_t &= \sigma(W_os_{t-1} + U_ox_t + b_o) \\
f_t &= \sigma(W_fs_{t-1} + U_fx_t + b_f) \\
\\
\tilde{s_t}& = \phi(W(o_t \odot s_{t-1}) + Ux_t + b)\\
s_t &= f_t \odot s_{t-1} + i_t \odot \tilde{s}_t
\end{split}
$$
LSTM内部数据流示意如下：
![LSTM](http://7xwp22.com1.z0.glb.clouddn.com/markdown/1488933056749.png)
在理论上，这个漂亮的原型应该是能工作的。但在实践中，所采取的选择性措施（通常）不足以克服LSTM的根本挑战：选择性忘记和选择性写入在训练开始时不协调，这可能导致状态快速变大和混乱。 此外，由于状态潜在地无界，所以门和候选写入将经常变得饱和，这导致训练的问题。

这个现象被Hochreiter和Schmidhuber（1997）观察到了，他们将问题称为“内部状态漂移”，因为“如果[写入]大多数是正的或大部分是负的，那么内部状态将随着时间的推移而趋于漂移。事实证明，这个问题是如此严重，以致我们创建的原型在实践中往往失败，即使有非常小的初始学习率和仔细选择的偏置初始化。 最清楚的实践证明可以参照[Greff et al（2015）](https://arxiv.org/abs/1503.04069)，其包含8个LSTM变体的经验比较。 基本上类似于上面的原型，通常不能收敛。

通过强制对状态的约束，防止它的爆炸，我们可以克服这个问题。 有几种方法来做到这一点，这导致LSTM的不同模型。


